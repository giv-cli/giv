# Configuration examples for giv

## Ollama Configuration
# Note: the Ollama CLI will use the GIV_MODEL variable or the CLI --model arg to determine which model to use.
### Basic setup for Ollama CLI
GIV_MODEL=qwen2.5-coder

# Note: When using remote generation, the GIV_API_MODEL variable or the CLI --api-model arg will determine which model to use

## Remote: groq API Configuration
GIV_API_URL="https://api.groq.com/openai/v1/chat/completions"
GIV_API_MODEL="compound-beta"
GIV_API_KEY=your_groq_api_key_here


## Remote OpenAI Compatible API Configuration

## OpenAI Configuration
### Basic setup for OpenAI
GIV_API_MODEL=gpt-4o-mini
GIV_API_URL=https://api.openai.com/v1/chat/completions
GIV_API_KEY=your_openai_api_key_here


## Azure OpenAI Configuration
### Using existing environment variables
# Assuming you have set the following environment variables in your system:
# AZURE_OPENAI_API_INSTANCE_NAME=<instance name>
# AZURE_OPENAI_API_KEY=<api key>
# AZURE_OPENAI_API_VERSION=<api version>
# AZURE_OPENAI_API_DEPLOYMENT_NAME=<deployment name>
# You can use them to define the giv configuration. Uncomment the following lines:

## If your deployment name and model name are different, set the model name here or use the --model flag in the CLI
# GIV_API_MODEL=$AZURE_OPENAI_API_DEPLOYMENT_NAME

## Create the proper API URL for Azure OpenAI
# GIV_API_URL="https://$AZURE_OPENAI_API_INSTANCE_NAME.openai.azure.com/openai/deployments/$AZURE_OPENAI_API_DEPLOYMENT_NAME/chat/completions?api-version=$AZURE_OPENAI_API_VERSION"

## Use the Azure OpenAI API key for authentication
# GIV_API_KEY=$AZURE_OPENAI_API_KEY

### Alternative: Directly set Azure OpenAI Configuration

## Set this to the name of your Azure OpenAI model
# GIV_API_MODEL=<MODEL NAME>

## Create the proper API URL for Azure OpenAI
# GIV_API_URL="https://<INSTANCE NAME>.openai.azure.com/openai/deployments/<DEPLOYMENT NAME>/chat/completions?api-version=<API VERSION>"

## Use the Azure OpenAI API key for authentication
# GIV_API_KEY=<API KEY>